{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e05adc1",
   "metadata": {},
   "source": [
    "# Task 2: Quantitative Analysis with PyNance and TA-Lib\n",
    "\n",
    "## Objective:\n",
    "Perform quantitative financial analysis using technical indicators and financial metrics to understand stock price movements and create professional trading visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d359854",
   "metadata": {},
   "source": [
    "1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53fdb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "print(\" Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1509b6",
   "metadata": {},
   "source": [
    "2. LOAD STOCK PRICE DATA FROM CSV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba9ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LOADING ALL STOCK DATA FILES\n",
      "=============================================\n",
      "Found 6 stock files in ../data/Data/:\n",
      "  ‚Ä¢ AAPL.csv\n",
      "  ‚Ä¢ AMZN.csv\n",
      "  ‚Ä¢ GOOG.csv\n",
      "  ‚Ä¢ META.csv\n",
      "  ‚Ä¢ MSFT.csv\n",
      "  ‚Ä¢ NVDA.csv\n",
      " AAPL: 3,774 rows loaded\n",
      " AMZN: 3,774 rows loaded\n",
      " GOOG: 3,774 rows loaded\n",
      " META: 2,923 rows loaded\n",
      " MSFT: 3,774 rows loaded\n",
      " NVDA: 3,774 rows loaded\n",
      "\n",
      " SUMMARY: Successfully loaded 6 stocks\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD ALL STOCK DATA FILES\n",
    "# =============================================================================\n",
    "\n",
    "print(\" LOADING ALL STOCK DATA FILES\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Define the data path\n",
    "data_path = '../data/Data/'\n",
    "\n",
    "# List all files in the Data directory\n",
    "try:\n",
    "    stock_files = os.listdir(data_path)\n",
    "    print(f\"Found {len(stock_files)} stock files in {data_path}:\")\n",
    "    for file in stock_files:\n",
    "        print(f\"  ‚Ä¢ {file}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\" Error: Directory {data_path} not found\")\n",
    "    stock_files = []\n",
    "\n",
    "# Load each stock file into a DataFrame\n",
    "stock_data = {}\n",
    "for stock_file in stock_files:\n",
    "    if stock_file.endswith('.csv'):\n",
    "        stock_name = stock_file.replace('.csv', '')  # Remove .csv extension\n",
    "        file_path = os.path.join(data_path, stock_file)\n",
    "        \n",
    "        try:\n",
    "            # Load the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            stock_data[stock_name] = df\n",
    "            print(f\" {stock_name}: {len(df):,} rows loaded\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error loading {stock_file}: {e}\")\n",
    "\n",
    "print(f\"\\n SUMMARY: Successfully loaded {len(stock_data)} stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edac0a5",
   "metadata": {},
   "source": [
    "3. CHECK REQUIRED COLUMNS FOR ALL STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4469071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CHECKING REQUIRED COLUMNS FOR ALL STOCKS\n",
      "=======================================================\n",
      "Required columns to check: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "\n",
      "=======================================================\n",
      "\n",
      " AAPL:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " AMZN:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " GOOG:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " META:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " MSFT:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " NVDA:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CHECK REQUIRED COLUMNS FOR ALL STOCKS\n",
    "# =============================================================================\n",
    "\n",
    "print(\" CHECKING REQUIRED COLUMNS FOR ALL STOCKS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "print(\"Required columns to check:\", required_columns)\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "\n",
    "for stock_name, df in stock_data.items():\n",
    "    print(f\"\\n {stock_name}:\")\n",
    "    print(f\"   Total columns: {len(df.columns)}\")\n",
    "    print(f\"   Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check for missing required columns\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"    MISSING COLUMNS: {missing_columns}\")\n",
    "        \n",
    "        # Try to find and map alternative column names\n",
    "        column_mapping = {\n",
    "            'OPEN': 'Open', 'HIGH': 'High', 'LOW': 'Low', \n",
    "            'CLOSE': 'Close', 'VOLUME': 'Volume'\n",
    "        }\n",
    "        \n",
    "        mappings_made = []\n",
    "        for alt_name, std_name in column_mapping.items():\n",
    "            if alt_name in df.columns and std_name not in df.columns:\n",
    "                df[std_name] = df[alt_name]\n",
    "                mappings_made.append(f\"{alt_name}‚Üí{std_name}\")\n",
    "        \n",
    "        if mappings_made:\n",
    "            print(f\"    MAPPED: {', '.join(mappings_made)}\")\n",
    "            \n",
    "        # Check again after mapping\n",
    "        still_missing = [col for col in required_columns if col not in df.columns]\n",
    "        if still_missing:\n",
    "            print(f\"    STILL MISSING: {still_missing}\")\n",
    "        else:\n",
    "            print(f\"    ALL REQUIRED COLUMNS NOW PRESENT\")\n",
    "    else:\n",
    "        print(f\"    ALL REQUIRED COLUMNS PRESENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f2378",
   "metadata": {},
   "source": [
    "4. ENSURE REQUIRED COLUMNS EXIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2bfb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CHECKING REQUIRED COLUMNS\n",
      "===================================\n",
      "\n",
      "AAPL:\n",
      "   All required columns present\n",
      "\n",
      "AMZN:\n",
      "   All required columns present\n",
      "\n",
      "GOOG:\n",
      "   All required columns present\n",
      "\n",
      "META:\n",
      "   All required columns present\n",
      "\n",
      "MSFT:\n",
      "   All required columns present\n",
      "\n",
      "NVDA:\n",
      "   All required columns present\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ENSURE REQUIRED COLUMNS EXIST\n",
    "# =============================================================================\n",
    "\n",
    "print(\" CHECKING REQUIRED COLUMNS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "for stock_name, df in stock_data.items():\n",
    "    print(f\"\\n{stock_name}:\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"   Missing: {missing_columns}\")\n",
    "        \n",
    "        # Try to find alternative column names\n",
    "        column_mapping = {\n",
    "            'OPEN': 'Open', 'HIGH': 'High', 'LOW': 'Low', \n",
    "            'CLOSE': 'Close', 'VOLUME': 'Volume'\n",
    "        }\n",
    "        \n",
    "        for alt_name, std_name in column_mapping.items():\n",
    "            if alt_name in df.columns and std_name not in df.columns:\n",
    "                df[std_name] = df[alt_name]\n",
    "                print(f\"  Mapped {alt_name} ‚Üí {std_name}\")\n",
    "    else:\n",
    "        print(f\"   All required columns present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649550e6",
   "metadata": {},
   "source": [
    "5. PREPARE DATA FOR ALL STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58a72658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PREPARING DATA FOR ALL STOCKS\n",
      "=============================================\n",
      "\n",
      " Preparing AAPL:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing AMZN:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing GOOG:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing META:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing MSFT:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing NVDA:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " PREPARATION SUMMARY:\n",
      "   ‚Ä¢ AAPL: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n",
      "   ‚Ä¢ AMZN: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n",
      "   ‚Ä¢ GOOG: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n",
      "   ‚Ä¢ META: 2,923 rows, 0 removed, 2012-05-18 to 2023-12-29\n",
      "   ‚Ä¢ MSFT: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n",
      "   ‚Ä¢ NVDA: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PREPARE DATA FOR ALL STOCKS\n",
    "# =============================================================================\n",
    "\n",
    "print(\" PREPARING DATA FOR ALL STOCKS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "preparation_summary = {}\n",
    "\n",
    "for stock_name, df in stock_data.items():\n",
    "    print(f\"\\n Preparing {stock_name}:\")\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    df_prepared = df.copy()\n",
    "    \n",
    "    # 1. Convert Date column to datetime\n",
    "    if 'Date' in df_prepared.columns:\n",
    "        df_prepared['Date'] = pd.to_datetime(df_prepared['Date'])\n",
    "        print(f\"    Date converted to datetime\")\n",
    "    elif 'DATE' in df_prepared.columns:\n",
    "        df_prepared['Date'] = pd.to_datetime(df_prepared['DATE'])\n",
    "        print(f\"    DATE converted to Date datetime\")\n",
    "    else:\n",
    "        print(f\"     No Date column found\")\n",
    "    \n",
    "    # 2. Sort by date (oldest to newest)\n",
    "    if 'Date' in df_prepared.columns:\n",
    "        df_prepared = df_prepared.sort_values('Date').reset_index(drop=True)\n",
    "        print(f\"    Data sorted by date\")\n",
    "    \n",
    "    # 3. Remove rows with missing required data\n",
    "    initial_rows = len(df_prepared)\n",
    "    df_prepared = df_prepared.dropna(subset=required_columns)\n",
    "    final_rows = len(df_prepared)\n",
    "    \n",
    "    rows_removed = initial_rows - final_rows\n",
    "    if rows_removed > 0:\n",
    "        print(f\"    Removed {rows_removed} rows with missing data\")\n",
    "    \n",
    "    # 4. Update the stock data with prepared DataFrame\n",
    "    stock_data[stock_name] = df_prepared\n",
    "    \n",
    "    # Store summary\n",
    "    preparation_summary[stock_name] = {\n",
    "        'initial_rows': initial_rows,\n",
    "        'final_rows': final_rows,\n",
    "        'rows_removed': rows_removed,\n",
    "        'date_range': f\"{df_prepared['Date'].min().strftime('%Y-%m-%d')} to {df_prepared['Date'].max().strftime('%Y-%m-%d')}\" if 'Date' in df_prepared.columns else 'N/A'\n",
    "    }\n",
    "\n",
    "print(f\"\\n PREPARATION SUMMARY:\")\n",
    "for stock_name, summary in preparation_summary.items():\n",
    "    print(f\"   ‚Ä¢ {stock_name}: {summary['final_rows']:,} rows, {summary['rows_removed']} removed, {summary['date_range']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bac9f5",
   "metadata": {},
   "source": [
    "6. FINAL DATA QUALITY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d10a3264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL DATA QUALITY REPORT\n",
      "========================================\n",
      "\n",
      " STOCKS READY FOR ANALYSIS: 6\n",
      "\n",
      "==================================================\n",
      " AAPL - DATA QUALITY REPORT\n",
      "==================================================\n",
      "‚Ä¢ Total trading days: 3,774\n",
      "‚Ä¢ Date range: 2009-01-02 to 2023-12-29\n",
      "‚Ä¢ Time span: 5474 days\n",
      "‚Ä¢ Missing values: 0\n",
      "‚Ä¢ Price statistics:\n",
      "  - Open: $53.80 (avg), $2.38-$196.17 (range)\n",
      "  - High: $54.38 (avg), $2.46-$197.75 (range)\n",
      "  - Low: $53.25 (avg), $2.35-$195.16 (range)\n",
      "  - Close: $53.84 (avg), $2.35-$196.26 (range)\n",
      "‚Ä¢ Volume: 264,063,974 (avg shares per day)\n",
      "‚Ä¢ Memory usage: 0.17 MB\n",
      "\n",
      "==================================================\n",
      " AMZN - DATA QUALITY REPORT\n",
      "==================================================\n",
      "‚Ä¢ Total trading days: 3,774\n",
      "‚Ä¢ Date range: 2009-01-02 to 2023-12-29\n",
      "‚Ä¢ Time span: 5474 days\n",
      "‚Ä¢ Missing values: 0\n",
      "‚Ä¢ Price statistics:\n",
      "  - Open: $59.42 (avg), $2.43-$187.20 (range)\n",
      "  - High: $60.12 (avg), $2.51-$188.65 (range)\n",
      "  - Low: $58.67 (avg), $2.38-$184.84 (range)\n",
      "  - Close: $59.41 (avg), $2.42-$186.57 (range)\n",
      "‚Ä¢ Volume: 91,851,835 (avg shares per day)\n",
      "‚Ä¢ Memory usage: 0.17 MB\n",
      "\n",
      "==================================================\n",
      " GOOG - DATA QUALITY REPORT\n",
      "==================================================\n",
      "‚Ä¢ Total trading days: 3,774\n",
      "‚Ä¢ Date range: 2009-01-02 to 2023-12-29\n",
      "‚Ä¢ Time span: 5474 days\n",
      "‚Ä¢ Missing values: 0\n",
      "‚Ä¢ Price statistics:\n",
      "  - Open: $50.75 (avg), $7.13-$150.83 (range)\n",
      "  - High: $51.29 (avg), $7.41-$151.07 (range)\n",
      "  - Low: $50.25 (avg), $6.99-$148.87 (range)\n",
      "  - Close: $50.78 (avg), $6.99-$149.68 (range)\n",
      "‚Ä¢ Volume: 61,230,955 (avg shares per day)\n",
      "‚Ä¢ Memory usage: 0.17 MB\n",
      "\n",
      "==================================================\n",
      " META - DATA QUALITY REPORT\n",
      "==================================================\n",
      "‚Ä¢ Total trading days: 2,923\n",
      "‚Ä¢ Date range: 2012-05-18 to 2023-12-29\n",
      "‚Ä¢ Time span: 4242 days\n",
      "‚Ä¢ Missing values: 0\n",
      "‚Ä¢ Price statistics:\n",
      "  - Open: $156.65 (avg), $17.97-$379.34 (range)\n",
      "  - High: $158.69 (avg), $18.16-$381.98 (range)\n",
      "  - Low: $154.69 (avg), $17.44-$376.49 (range)\n",
      "  - Close: $156.73 (avg), $17.62-$379.84 (range)\n",
      "‚Ä¢ Volume: 30,606,153 (avg shares per day)\n",
      "‚Ä¢ Memory usage: 0.13 MB\n",
      "\n",
      "==================================================\n",
      " MSFT - DATA QUALITY REPORT\n",
      "==================================================\n",
      "‚Ä¢ Total trading days: 3,774\n",
      "‚Ä¢ Date range: 2009-01-02 to 2023-12-29\n",
      "‚Ä¢ Time span: 5474 days\n",
      "‚Ä¢ Missing values: 0\n",
      "‚Ä¢ Price statistics:\n",
      "  - Open: $102.42 (avg), $11.20-$378.83 (range)\n",
      "  - High: $103.44 (avg), $11.51-$379.36 (range)\n",
      "  - Low: $101.37 (avg), $10.95-$373.30 (range)\n",
      "  - Close: $102.46 (avg), $11.16-$377.78 (range)\n",
      "‚Ä¢ Volume: 38,957,537 (avg shares per day)\n",
      "‚Ä¢ Memory usage: 0.17 MB\n",
      "\n",
      "==================================================\n",
      " NVDA - DATA QUALITY REPORT\n",
      "==================================================\n",
      "‚Ä¢ Total trading days: 3,774\n",
      "‚Ä¢ Date range: 2009-01-02 to 2023-12-29\n",
      "‚Ä¢ Time span: 5474 days\n",
      "‚Ä¢ Missing values: 0\n",
      "‚Ä¢ Price statistics:\n",
      "  - Open: $6.79 (avg), $0.17-$50.18 (range)\n",
      "  - High: $6.92 (avg), $0.17-$50.52 (range)\n",
      "  - Low: $6.67 (avg), $0.16-$49.39 (range)\n",
      "  - Close: $6.80 (avg), $0.17-$50.38 (range)\n",
      "‚Ä¢ Volume: 523,075,307 (avg shares per day)\n",
      "‚Ä¢ Memory usage: 0.17 MB\n",
      "\n",
      "  All stock data loaded and prepared!\n",
      "   ‚Ä¢ 6 stocks ready for technical analysis\n",
      "   ‚Ä¢ Required columns verified: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "   ‚Ä¢ Data cleaned and sorted\n",
      "   ‚Ä¢ Ready for next step: Technical Indicators\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  FINAL DATA QUALITY REPORT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"FINAL DATA QUALITY REPORT\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"\\n STOCKS READY FOR ANALYSIS: {len(stock_data)}\")\n",
    "\n",
    "for stock_name, df in stock_data.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" {stock_name} - DATA QUALITY REPORT\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    print(f\"‚Ä¢ Total trading days: {len(df):,}\")\n",
    "    \n",
    "    if 'Date' in df.columns:\n",
    "        print(f\"‚Ä¢ Date range: {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "        date_range_days = (df['Date'].max() - df['Date'].min()).days\n",
    "        print(f\"‚Ä¢ Time span: {date_range_days} days\")\n",
    "    \n",
    "    # Check missing values\n",
    "    missing_counts = df[required_columns].isnull().sum()\n",
    "    total_missing = missing_counts.sum()\n",
    "    print(f\"‚Ä¢ Missing values: {total_missing}\")\n",
    "    \n",
    "    # Price statistics\n",
    "    print(f\"‚Ä¢ Price statistics:\")\n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        if col in df.columns:\n",
    "            print(f\"  - {col}: ${df[col].mean():.2f} (avg), ${df[col].min():.2f}-${df[col].max():.2f} (range)\")\n",
    "    \n",
    "    if 'Volume' in df.columns:\n",
    "        print(f\"‚Ä¢ Volume: {df['Volume'].mean():,.0f} (avg shares per day)\")\n",
    "    \n",
    "    print(f\"‚Ä¢ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\n  All stock data loaded and prepared!\")\n",
    "print(f\"   ‚Ä¢ {len(stock_data)} stocks ready for technical analysis\")\n",
    "print(f\"   ‚Ä¢ Required columns verified: {required_columns}\")\n",
    "print(f\"   ‚Ä¢ Data cleaned and sorted\")\n",
    "print(f\"   ‚Ä¢ Ready for next step: Technical Indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e98438",
   "metadata": {},
   "source": [
    " ##  Apply Technical Indicators with TA-Lib\n",
    "\n",
    "### Objectives:\n",
    "- Calculate Moving Averages (20, 50, 200 days)\n",
    "- Compute RSI (Relative Strength Index) \n",
    "- Generate MACD (Moving Average Convergence Divergence)\n",
    "- Add Bollinger Bands and additional indicators\n",
    "- Ensure accuracy and professional calculation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1f859",
   "metadata": {},
   "source": [
    "7. CALCULATE TECHNICAL INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "393499e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CALCULATING TECHNICAL INDICATORS\n",
      "==================================================\n",
      " pandas_ta imported successfully\n",
      "\n",
      " Calculating indicators for AAPL (3774 trading days)\n",
      "\n",
      " 1. CALCULATING MOVING AVERAGES...\n",
      "    20, 50, 200-day Simple Moving Averages\n",
      " 2. CALCULATING RSI...\n",
      "    14-period RSI\n",
      " 3. CALCULATING MACD...\n",
      "   MACD columns returned: ['MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9']\n",
      "    MACD (12,26,9) with Signal Line and Histogram\n",
      "üìè 4. CALCULATING BOLLINGER BANDS...\n",
      "   Bollinger Band columns returned: ['BBL_20_2.0_2.0', 'BBM_20_2.0_2.0', 'BBU_20_2.0_2.0', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0']\n",
      "    Bollinger Bands (20-period, 2 std)\n",
      " 5. CALCULATING ADDITIONAL INDICATORS...\n",
      "    Average True Range (ATR)\n",
      "    Stochastic Oscillator\n",
      "\n",
      " TECHNICAL INDICATORS CALCULATION COMPLETE!\n",
      "   ‚Ä¢ Major technical indicators calculated\n",
      "   ‚Ä¢ All indicators use standard professional parameters\n",
      "\n",
      " INDICATORS SUCCESSFULLY ADDED:\n",
      "   ‚Ä¢ MA_20\n",
      "   ‚Ä¢ MA_50\n",
      "   ‚Ä¢ MA_200\n",
      "   ‚Ä¢ RSI\n",
      "   ‚Ä¢ MACD\n",
      "   ‚Ä¢ MACD_Signal\n",
      "   ‚Ä¢ MACD_Hist\n",
      "   ‚Ä¢ BB_Upper\n",
      "   ‚Ä¢ BB_Middle\n",
      "   ‚Ä¢ BB_Lower\n",
      "   ‚Ä¢ ATR\n",
      "   ‚Ä¢ Stochastic_K\n",
      "   ‚Ä¢ Stochastic_D\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  CALCULATE TECHNICAL INDICATORS WITH PANDAS-TA\n",
    "# =============================================================================\n",
    "\n",
    "print(\" CALCULATING TECHNICAL INDICATORS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Import technical analysis library\n",
    "try:\n",
    "    import pandas_ta as ta\n",
    "    print(\" pandas_ta imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\" Error importing pandas_ta: {e}\")\n",
    "    print(\" Run: pip install pandas-ta\")\n",
    "\n",
    "# We'll use AAPL as our primary example for detailed analysis\n",
    "aapl_df = stock_data['AAPL'].copy()\n",
    "\n",
    "print(f\"\\n Calculating indicators for AAPL ({len(aapl_df)} trading days)\")\n",
    "\n",
    "# 1. MOVING AVERAGES\n",
    "print(\"\\n 1. CALCULATING MOVING AVERAGES...\")\n",
    "aapl_df['MA_20'] = ta.sma(aapl_df['Close'], length=20)\n",
    "aapl_df['MA_50'] = ta.sma(aapl_df['Close'], length=50)\n",
    "aapl_df['MA_200'] = ta.sma(aapl_df['Close'], length=200)\n",
    "print(\"    20, 50, 200-day Simple Moving Averages\")\n",
    "\n",
    "# 2. RELATIVE STRENGTH INDEX (RSI)\n",
    "print(\" 2. CALCULATING RSI...\")\n",
    "aapl_df['RSI'] = ta.rsi(aapl_df['Close'], length=14)\n",
    "print(\"    14-period RSI\")\n",
    "\n",
    "# 3. MACD (MOVING AVERAGE CONVERGENCE DIVERGENCE)\n",
    "print(\" 3. CALCULATING MACD...\")\n",
    "macd_data = ta.macd(aapl_df['Close'], fast=12, slow=26, signal=9)\n",
    "# Check what columns are actually returned\n",
    "print(f\"   MACD columns returned: {list(macd_data.columns) if macd_data is not None else 'None'}\")\n",
    "aapl_df['MACD'] = macd_data.iloc[:, 0]  # First column is MACD line\n",
    "aapl_df['MACD_Signal'] = macd_data.iloc[:, 1]  # Second column is Signal line\n",
    "aapl_df['MACD_Hist'] = macd_data.iloc[:, 2]  # Third column is Histogram\n",
    "print(\"    MACD (12,26,9) with Signal Line and Histogram\")\n",
    "\n",
    "# 4. BOLLINGER BANDS - FIXED VERSION\n",
    "print(\"üìè 4. CALCULATING BOLLINGER BANDS...\")\n",
    "bb_data = ta.bbands(aapl_df['Close'], length=20, std=2)\n",
    "# Check what columns are actually returned\n",
    "print(f\"   Bollinger Band columns returned: {list(bb_data.columns) if bb_data is not None else 'None'}\")\n",
    "\n",
    "if bb_data is not None:\n",
    "    # Use the actual column names returned\n",
    "    bb_columns = list(bb_data.columns)\n",
    "    if len(bb_columns) >= 3:\n",
    "        aapl_df['BB_Upper'] = bb_data.iloc[:, 0]  # First column\n",
    "        aapl_df['BB_Middle'] = bb_data.iloc[:, 1]  # Second column  \n",
    "        aapl_df['BB_Lower'] = bb_data.iloc[:, 2]  # Third column\n",
    "        print(\"    Bollinger Bands (20-period, 2 std)\")\n",
    "    else:\n",
    "        print(\"    Not enough Bollinger Band columns returned\")\n",
    "else:\n",
    "    print(\"    Bollinger Bands calculation failed\")\n",
    "\n",
    "# 5. ADDITIONAL INDICATORS\n",
    "print(\" 5. CALCULATING ADDITIONAL INDICATORS...\")\n",
    "# Average True Range (Volatility)\n",
    "atr_data = ta.atr(aapl_df['High'], aapl_df['Low'], aapl_df['Close'], length=14)\n",
    "if atr_data is not None:\n",
    "    aapl_df['ATR'] = atr_data\n",
    "    print(\"    Average True Range (ATR)\")\n",
    "else:\n",
    "    print(\"    ATR calculation failed\")\n",
    "\n",
    "# Stochastic Oscillator\n",
    "stoch_data = ta.stoch(aapl_df['High'], aapl_df['Low'], aapl_df['Close'])\n",
    "if stoch_data is not None:\n",
    "    stoch_columns = list(stoch_data.columns)\n",
    "    if len(stoch_columns) >= 2:\n",
    "        aapl_df['Stochastic_K'] = stoch_data.iloc[:, 0]  # First column\n",
    "        aapl_df['Stochastic_D'] = stoch_data.iloc[:, 1]  # Second column\n",
    "        print(\"    Stochastic Oscillator\")\n",
    "    else:\n",
    "        print(\"    Not enough Stochastic columns returned\")\n",
    "else:\n",
    "    print(\"    Stochastic calculation failed\")\n",
    "\n",
    "print(f\"\\n TECHNICAL INDICATORS CALCULATION COMPLETE!\")\n",
    "print(f\"   ‚Ä¢ Major technical indicators calculated\")\n",
    "print(f\"   ‚Ä¢ All indicators use standard professional parameters\")\n",
    "\n",
    "# Display the actual column names we have\n",
    "print(f\"\\n INDICATORS SUCCESSFULLY ADDED:\")\n",
    "new_columns = [col for col in aapl_df.columns if col not in ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "for col in new_columns:\n",
    "    print(f\"   ‚Ä¢ {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f19403",
   "metadata": {},
   "source": [
    "8. INDICATOR ACCURACY AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef44017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " INDICATOR ACCURACY CHECK\n",
      "=============================================\n",
      " VALIDATING INDICATOR CALCULATIONS:\n",
      "   ‚úÖ Moving Average 20-day: 19 NaN, 0 infinite, latest: 192.49063262939455\n",
      "   ‚ö†Ô∏è Moving Average 50-day: 49 NaN, 0 infinite, latest: 184.81482818603516\n",
      "   ‚ö†Ô∏è Moving Average 200-day: 199 NaN, 0 infinite, latest: 177.4520985412598\n",
      "   ‚úÖ Relative Strength Index: 1 NaN, 0 infinite, latest: 51.12134654746493\n",
      "   ‚ö†Ô∏è MACD Line: 25 NaN, 0 infinite, latest: 1.5595388382318731\n",
      "   ‚ö†Ô∏è MACD Signal Line: 33 NaN, 0 infinite, latest: -0.8651012876028337\n",
      "   ‚úÖ Bollinger Upper Band: 19 NaN, 0 infinite, latest: 188.01996363752482\n",
      "   ‚úÖ Bollinger Lower Band: 19 NaN, 0 infinite, latest: 196.96130162126428\n",
      "   ‚úÖ Average True Range: 13 NaN, 0 infinite, latest: 2.5516892107723286\n",
      "\n",
      " CURRENT TECHNICAL SIGNALS (Latest Values):\n",
      "   ‚Ä¢ Price: $190.73\n",
      "   ‚Ä¢ RSI: 51.1 (Neutral)\n",
      "   ‚Ä¢ MACD: 1.560 (Bullish)\n",
      "   ‚Ä¢ Price vs MA_20: Below (Bearish)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  INDICATOR ACCURACY AND VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\" INDICATOR ACCURACY CHECK\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Check for any calculation errors or invalid values\n",
    "indicators_to_check = {\n",
    "    'MA_20': 'Moving Average 20-day',\n",
    "    'MA_50': 'Moving Average 50-day', \n",
    "    'MA_200': 'Moving Average 200-day',\n",
    "    'RSI': 'Relative Strength Index',\n",
    "    'MACD': 'MACD Line',\n",
    "    'MACD_Signal': 'MACD Signal Line',\n",
    "    'BB_Upper': 'Bollinger Upper Band',\n",
    "    'BB_Lower': 'Bollinger Lower Band',\n",
    "    'ATR': 'Average True Range'\n",
    "}\n",
    "\n",
    "print(\" VALIDATING INDICATOR CALCULATIONS:\")\n",
    "\n",
    "validation_results = {}\n",
    "for indicator, description in indicators_to_check.items():\n",
    "    if indicator in aapl_df.columns:\n",
    "        # Check for NaN values (first few rows expected for moving averages)\n",
    "        nan_count = aapl_df[indicator].isna().sum()\n",
    "        infinite_count = np.isinf(aapl_df[indicator]).sum()\n",
    "        \n",
    "        validation_results[indicator] = {\n",
    "            'description': description,\n",
    "            'nan_count': nan_count,\n",
    "            'infinite_count': infinite_count,\n",
    "            'latest_value': aapl_df[indicator].iloc[-1] if not pd.isna(aapl_df[indicator].iloc[-1]) else 'NaN'\n",
    "        }\n",
    "        \n",
    "        status = \"‚úÖ\" if nan_count <= 20 and infinite_count == 0 else \"‚ö†Ô∏è\"\n",
    "        print(f\"   {status} {description}: {nan_count} NaN, {infinite_count} infinite, latest: {validation_results[indicator]['latest_value']}\")\n",
    "\n",
    "print(f\"\\n CURRENT TECHNICAL SIGNALS (Latest Values):\")\n",
    "current_price = aapl_df['Close'].iloc[-1]\n",
    "print(f\"   ‚Ä¢ Price: ${current_price:.2f}\")\n",
    "print(f\"   ‚Ä¢ RSI: {aapl_df['RSI'].iloc[-1]:.1f} ({'Oversold' if aapl_df['RSI'].iloc[-1] < 30 else 'Overbought' if aapl_df['RSI'].iloc[-1] > 70 else 'Neutral'})\")\n",
    "print(f\"   ‚Ä¢ MACD: {aapl_df['MACD'].iloc[-1]:.3f} ({'Bullish' if aapl_df['MACD'].iloc[-1] > aapl_df['MACD_Signal'].iloc[-1] else 'Bearish'})\")\n",
    "print(f\"   ‚Ä¢ Price vs MA_20: {'Above' if current_price > aapl_df['MA_20'].iloc[-1] else 'Below'} ({'Bullish' if current_price > aapl_df['MA_20'].iloc[-1] else 'Bearish'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b949a4d",
   "metadata": {},
   "source": [
    "##  Financial Metrics with PyNance\n",
    "\n",
    "### Objectives:\n",
    "- Calculate daily and cumulative returns\n",
    "- Compute volatility measures\n",
    "- Generate risk-adjusted performance metrics (Sharpe Ratio)\n",
    "- Analyze drawdowns and performance statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dae489",
   "metadata": {},
   "source": [
    "9. CALCULATE FINANCIAL METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f803dbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CALCULATING FINANCIAL METRICS\n",
      "=============================================\n",
      "\n",
      " 1. CALCULATING RETURNS AND PERFORMANCE...\n",
      " 2. CALCULATING VOLATILITY METRICS...\n",
      " 3. CALCULATING PERFORMANCE METRICS...\n",
      " FINANCIAL METRICS CALCULATED:\n",
      "   ‚Ä¢ Daily and Cumulative Returns\n",
      "   ‚Ä¢ 20-day and 50-day Rolling Volatility\n",
      "   ‚Ä¢ Logarithmic Returns\n",
      "\n",
      " PERFORMANCE SUMMARY:\n",
      "   ‚Ä¢ Total Return: 6907.74%\n",
      "   ‚Ä¢ Annualized Volatility: 28.59%\n",
      "   ‚Ä¢ Sharpe Ratio: 1.136\n",
      "   ‚Ä¢ Maximum Drawdown: -43.80%\n",
      "\n",
      "üî¨ 4. PYNANCE INTEGRATION (Optional)...\n",
      "    PyNance not available - using standard pandas calculations\n",
      "    Optional: pip install pynance\n",
      "    Note: All essential metrics already calculated above\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE FINANCIAL METRICS\n",
    "# =============================================================================\n",
    "\n",
    "print(\" CALCULATING FINANCIAL METRICS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# 1. BASIC RETURN CALCULATIONS\n",
    "print(\"\\n 1. CALCULATING RETURNS AND PERFORMANCE...\")\n",
    "aapl_df['Daily_Return'] = aapl_df['Close'].pct_change()\n",
    "aapl_df['Cumulative_Return'] = (1 + aapl_df['Daily_Return']).cumprod()\n",
    "aapl_df['Log_Return'] = np.log(aapl_df['Close'] / aapl_df['Close'].shift(1))\n",
    "\n",
    "# 2. VOLATILITY MEASURES\n",
    "print(\" 2. CALCULATING VOLATILITY METRICS...\")\n",
    "aapl_df['Volatility_20d'] = aapl_df['Daily_Return'].rolling(window=20).std()\n",
    "aapl_df['Volatility_50d'] = aapl_df['Daily_Return'].rolling(window=50).std()\n",
    "\n",
    "# 3. PERFORMANCE METRICS\n",
    "print(\" 3. CALCULATING PERFORMANCE METRICS...\")\n",
    "\n",
    "# Total return\n",
    "total_return = (aapl_df['Close'].iloc[-1] / aapl_df['Close'].iloc[0] - 1) * 100\n",
    "\n",
    "# Annualized volatility (assuming 252 trading days)\n",
    "if len(aapl_df) > 252:\n",
    "    annual_volatility = aapl_df['Daily_Return'].std() * np.sqrt(252) * 100\n",
    "else:\n",
    "    annual_volatility = aapl_df['Daily_Return'].std() * np.sqrt(len(aapl_df)) * 100\n",
    "\n",
    "# Sharpe Ratio (assuming 0% risk-free rate for simplicity)\n",
    "sharpe_ratio = aapl_df['Daily_Return'].mean() / aapl_df['Daily_Return'].std() * np.sqrt(252)\n",
    "\n",
    "# Maximum Drawdown\n",
    "rolling_max = aapl_df['Close'].cummax()\n",
    "daily_drawdown = aapl_df['Close'] / rolling_max - 1\n",
    "max_drawdown = daily_drawdown.min() * 100\n",
    "\n",
    "print(\" FINANCIAL METRICS CALCULATED:\")\n",
    "print(f\"   ‚Ä¢ Daily and Cumulative Returns\")\n",
    "print(f\"   ‚Ä¢ 20-day and 50-day Rolling Volatility\")\n",
    "print(f\"   ‚Ä¢ Logarithmic Returns\")\n",
    "\n",
    "print(f\"\\n PERFORMANCE SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Total Return: {total_return:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Annualized Volatility: {annual_volatility:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "print(f\"   ‚Ä¢ Maximum Drawdown: {max_drawdown:.2f}%\")\n",
    "\n",
    "# 4. PYNANCE INTEGRATION (OPTIONAL)\n",
    "print(\"\\nüî¨ 4. PYNANCE INTEGRATION (Optional)...\")\n",
    "try:\n",
    "    # Try to import PyNance\n",
    "    import pynance as pn\n",
    "    print(\"    PyNance successfully imported\")\n",
    "    \n",
    "    # Example PyNance usage (if you want to add specific metrics)\n",
    "    # pn_returns = pn.returns.log(aapl_df['Close'])\n",
    "    # print(f\"   ‚Ä¢ PyNance logarithmic returns calculated\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"    PyNance not available - using standard pandas calculations\")\n",
    "    print(\"    Optional: pip install pynance\")\n",
    "    print(\"    Note: All essential metrics already calculated above\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2fe96b",
   "metadata": {},
   "source": [
    "##  Visualize Data and Indicator Impact\n",
    "\n",
    "### Visualization Goals:\n",
    "- Create professional trading dashboard\n",
    "- Show relationship between price and technical indicators\n",
    "- Demonstrate impact of indicators on trading decisions\n",
    "- Provide clear, actionable insights for stock analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed2c81",
   "metadata": {},
   "source": [
    "10. Create Comprehensive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e338ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
